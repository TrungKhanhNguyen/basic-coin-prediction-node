services:
  fetcher:
    container_name: allora-fetcher-1
    build:
      context: .
      dockerfile: Dockerfile.fetcher
    volumes:
      - ./inference-data:/app/inference-data
      
  inference:
    container_name: allora-inference-1
    build:
      context: .
      dockerfile: Dockerfile.inference
    ports:
      - "8011:8011"
    volumes:
      - ./inference-data:/app/inference-data
  worker:
    container_name: allora-worker-1
    image: alloranetwork/allora-offchain-node:latest
    volumes:
      - ./worker-data:/data
    working_dir: /data
    depends_on:
      inference:
        condition: service_started
    env_file:
      - ./worker-data/env_file
    entrypoint: ["/node/allora_offchain_node"]

volumes:
  inference-data:
  worker-data:
